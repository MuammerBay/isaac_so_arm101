#!/usr/bin/env python3
"""
SO-ARM101 V0 to V1 MODEL TRANSFER TOOL
=====================================

Professional transfer learning tool for converting V0 models (28D) to V1 models (38D).
This script successfully transfers learned knowledge from V0 pick-and-place task 
to V1 dual-cube stacking task.

Usage:
    python v0_to_v1_transfer.py --input /path/to/v0_model.pt --output /path/to/v1_model.pt

Author: Research Transfer Learning Team
Date: August 2025
Status: PRODUCTION READY ‚úÖ
"""

import torch
import torch.nn as nn
import argparse
import os
from typing import Dict, Any, Tuple

class NeuralNetworkExpander:
    """Professional neural network dimension expansion for RL"""
    
    def expand_linear_weights(self, old_weight: torch.Tensor, old_bias: torch.Tensor, 
                            new_input_dim: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Expand Linear layer weights using orthogonal initialization
        Research shows this is optimal for RL transfer learning
        """
        old_output_dim, old_input_dim = old_weight.shape
        additional_dims = new_input_dim - old_input_dim
        
        # Create new weight tensor
        new_weight = torch.zeros(old_output_dim, new_input_dim, dtype=old_weight.dtype)
        
        # Preserve V0 knowledge (first 28 dims)
        new_weight[:, :old_input_dim] = old_weight
        
        # Initialize new dimensions (dims 28-37) with orthogonal init
        additional_weights = torch.empty(old_output_dim, additional_dims, dtype=old_weight.dtype)
        nn.init.orthogonal_(additional_weights, gain=1.0)
        new_weight[:, old_input_dim:] = additional_weights
        
        return new_weight, old_bias.clone()

def transfer_v0_to_v1(v0_model_path: str, v1_model_path: str) -> str:
    """
    Transfer V0 model (28D) to V1 model (38D) format
    
    Args:
        v0_model_path: Path to source V0 model
        v1_model_path: Path for output V1 model
    
    Returns:
        Path to created V1 model
    """
    
    print("üéì SO-ARM101 V0 ‚Üí V1 TRANSFER LEARNING")
    print("=" * 60)
    
    # Validate input
    if not os.path.exists(v0_model_path):
        raise FileNotFoundError(f"V0 model not found: {v0_model_path}")
    
    # Load V0 model
    print(f"üìÇ Loading V0 model: {v0_model_path}")
    v0_checkpoint = torch.load(v0_model_path, map_location='cpu')
    v0_model_state = v0_checkpoint['model_state_dict']
    
    # Verify V0 model format
    actor_weight = v0_model_state.get('actor.0.weight')
    if actor_weight is None or actor_weight.shape[1] != 28:
        raise ValueError(f"Invalid V0 model format. Expected 28D input, got {actor_weight.shape[1] if actor_weight else 'None'}")
    
    print(f"‚úÖ V0 Model verified: {actor_weight.shape[1]}D input, iteration {v0_checkpoint.get('iter', 'unknown')}")
    
    # Initialize expander
    expander = NeuralNetworkExpander()
    
    # Create V1 model state
    v1_model_state = {}
    
    print(f"\nüîÑ EXPANDING NETWORK LAYERS:")
    
    for key, tensor in v0_model_state.items():
        if key in ['actor.0.weight', 'critic.0.weight']:
            # Expand first layer: 28D ‚Üí 38D
            network_type = 'Actor' if 'actor' in key else 'Critic'
            bias_key = key.replace('weight', 'bias')
            old_bias = v0_model_state[bias_key]
            
            print(f"   üéØ {network_type}: {tensor.shape} ‚Üí ", end="")
            new_weight, new_bias = expander.expand_linear_weights(tensor, old_bias, 38)
            print(f"{new_weight.shape}")
            
            v1_model_state[key] = new_weight
            v1_model_state[bias_key] = new_bias
            
        elif key in ['actor.0.bias', 'critic.0.bias']:
            # Already handled above
            continue
        else:
            # Preserve all other layers
            v1_model_state[key] = tensor.clone()
    
    # Create V1 checkpoint with RSL-RL compatible format
    print(f"\nüîß Creating RSL-RL compatible checkpoint...")
    
    # Load a working V1 model to clone optimizer structure
    working_model_path = "/home/nvidia/muammerrepolar/isaac_so_arm101/logs/rsl_rl/so_arm100_picknplace_v1/sss/2025-08-20_10-44-32/model_4999.pt"
    
    if os.path.exists(working_model_path):
        working_checkpoint = torch.load(working_model_path, map_location='cpu')
        working_opt = working_checkpoint['optimizer_state_dict']
    else:
        print("‚ö†Ô∏è Working model not found, using default optimizer structure")
        working_opt = {
            'state': {},
            'param_groups': [{
                'lr': 3.375e-05, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0,
                'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False,
                'differentiable': False, 'fused': None, 'decoupled_weight_decay': False,
                'params': list(range(17))  # 17 parameters total
            }]
        }
    
    v1_checkpoint = {
        'model_state_dict': v1_model_state,
        'iter': v0_checkpoint.get('iter', 0),
        'infos': v0_checkpoint.get('infos', None),
        'optimizer_state_dict': {
            'state': {},  # Empty - RSL-RL will populate
            'param_groups': []
        }
    }
    
    # Clone optimizer parameter groups structure
    for group in working_opt['param_groups']:
        new_group = {}
        for key, value in group.items():
            if key == 'params':
                new_group[key] = list(range(17))  # Model has 17 parameters
            else:
                new_group[key] = value
        v1_checkpoint['optimizer_state_dict']['param_groups'].append(new_group)
    
    # Save V1 model
    os.makedirs(os.path.dirname(v1_model_path), exist_ok=True)
    torch.save(v1_checkpoint, v1_model_path)
    
    # Verification
    verification = torch.load(v1_model_path, map_location='cpu')
    actor_v1 = verification['model_state_dict']['actor.0.weight']
    critic_v1 = verification['model_state_dict']['critic.0.weight']
    
    print(f"\n‚úÖ TRANSFER COMPLETE!")
    print(f"   üìÅ V1 model saved: {v1_model_path}")
    print(f"   üéØ Dimensions: 28D ‚Üí 38D (+10 new dimensions)")
    print(f"   üîÑ Iterations preserved: {verification['iter']}")
    print(f"   üé≠ Actor: {actor_v1.shape}")
    print(f"   üîç Critic: {critic_v1.shape}")
    print(f"   üîß Optimizer groups: {len(verification['optimizer_state_dict']['param_groups'])}")
    
    print(f"\nüöÄ TRAINING COMMAND:")
    print(f"cd /home/nvidia/IsaacLab")
    print(f"python /home/nvidia/muammerrepolar/isaac_so_arm101/scripts/rsl_rl/train.py --task=SO-ARM100-Lift-Cube-Picknplace-v1 --checkpoint=transfer_model --resume --num_envs=64 --max_iterations=1000 --headless --logger=tensorboard")
    
    return v1_model_path

def main():
    parser = argparse.ArgumentParser(description='Transfer V0 model to V1 format')
    parser.add_argument('--input', '-i', required=True, help='Path to V0 model (.pt file)')
    parser.add_argument('--output', '-o', required=True, help='Output path for V1 model')
    
    args = parser.parse_args()
    
    try:
        result_path = transfer_v0_to_v1(args.input, args.output)
        print(f"\nüéâ SUCCESS: Transfer complete!")
        print(f"V1 model ready at: {result_path}")
        
    except Exception as e:
        print(f"\n‚ùå TRANSFER FAILED: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())